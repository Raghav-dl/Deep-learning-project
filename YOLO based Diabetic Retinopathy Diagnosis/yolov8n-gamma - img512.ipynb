{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27167ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbae8310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b0483d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3050 Laptop GPU'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e71906-6764-41ef-808e-3c047f95adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics.yolo.engine.model import YOLO\n",
    "\n",
    "from ultralytics import YOLO\n",
    "# model = YOLO(\"yolov8n.pt\") \n",
    "# model.to('cuda')\n",
    "# Load a model\n",
    "# model = YOLO('yolov8n-cls.yaml')  # build a new model from YAML\n",
    "model = YOLO('yolov8n-cls.pt')  # load a pretrained model (recommended for training)\n",
    "# model = YOLO('yolov8n-cls.yaml').load('yolov8n-cls.pt')  # build from YAML and transfer weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d7b653-5803-4a38-acde-497cd163ebf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RAGHAV\\\\SDP_DR'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dea4c6a-6635-439b-92f3-5c1d7746a086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.31 üöÄ Python-3.9.19 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:\\SDP\\DR\\gamma Dataset, epochs=30, time=None, patience=100, batch=32, imgsz=512, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train18, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train18\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\SDP\\DR\\gamma Dataset\\train... found 24192 images in 5 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\SDP\\DR\\gamma Dataset\\val... found 663 images in 5 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    336645  ultralytics.nn.modules.head.Classify         [256, 5]                      \n",
      "YOLOv8n-cls summary: 99 layers, 1444693 parameters, 1444693 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\classify\\train18', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\SDP\\DR\\gamma Dataset\\train... 24192 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24192/24192 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\SDP\\DR\\gamma Dataset\\val... 663 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 663/663 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train18\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30      1.77G       1.16         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:49<00:00,  2.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:04<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.695          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30      1.75G     0.8847         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:43<00:00,  2.20it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:05<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.763          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30      1.75G     0.8276         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:37<00:00,  2.24it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:04<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.759          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30      1.75G     0.7637         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:29<00:00,  2.29it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:05<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.748          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30      1.75G     0.6835         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [06:05<00:00,  2.07it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:06<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.769          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30      1.75G     0.6119         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [06:19<00:00,  1.99it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:05<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.807          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30      1.75G     0.5827         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:53<00:00,  2.14it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:06<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.783          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30      1.75G     0.5303         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:50<00:00,  2.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:04<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.774          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30      1.75G     0.4878         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:32<00:00,  2.27it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:05<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.79          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30      1.75G     0.4514         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:36<00:00,  2.25it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.777          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30      1.75G     0.4248         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:28<00:00,  2.30it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:04<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.784          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30      1.75G     0.3923         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:28<00:00,  2.30it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:04<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.802          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30      1.75G     0.3613         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:25<00:00,  2.32it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:04<00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.81          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30      1.75G     0.3432         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:17<00:00,  2.38it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:05<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.81          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30      1.75G     0.3208         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:18<00:00,  2.37it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:05<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.781          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30      1.75G     0.3033         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:22<00:00,  2.35it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:04<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.802          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30      1.75G     0.2853         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:20<00:00,  2.36it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:05<00:00,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.833          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30      1.75G     0.2619         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:17<00:00,  2.38it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:04<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.81          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30      1.75G     0.2455         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:19<00:00,  2.37it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:03<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.807          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30      1.75G     0.2204         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:17<00:00,  2.38it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:04<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.822          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30      1.75G     0.2153         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:26<00:00,  2.32it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:05<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.836          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30      1.75G     0.2036         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:26<00:00,  2.31it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:05<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.811          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30      1.75G     0.1858         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:26<00:00,  2.32it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:04<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.822          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30      1.75G     0.1694         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:24<00:00,  2.33it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:05<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.81          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30      1.75G     0.1646         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:23<00:00,  2.33it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:05<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.813          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30      1.75G     0.1515         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:25<00:00,  2.32it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:05<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.828          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30      1.75G     0.1453         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:26<00:00,  2.31it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:04<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.811          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30      1.75G      0.135         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:26<00:00,  2.32it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:03<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.813          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30      1.75G     0.1253         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:27<00:00,  2.31it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:04<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.817          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30      1.75G     0.1171         32        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 756/756 [05:32<00:00,  2.27it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:04<00:00,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.819          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 2.821 hours.\n",
      "Optimizer stripped from runs\\classify\\train18\\weights\\last.pt, 3.0MB\n",
      "Optimizer stripped from runs\\classify\\train18\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating runs\\classify\\train18\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.31 üöÄ Python-3.9.19 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1441285 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\SDP\\DR\\gamma Dataset\\train... found 24192 images in 5 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\SDP\\DR\\gamma Dataset\\val... found 663 images in 5 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:05<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.836          1\n",
      "Speed: 0.7ms preprocess, 1.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\train18\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\train18\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "results = model.train(data='C:\\SDP\\DR\\gamma Dataset', epochs=30, patience=100, batch=32, imgsz=512, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, exist_ok=False, pretrained=True, optimizer='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ec6c133-87d4-450a-b893-965bdf9a5889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.31 üöÄ Python-3.9.19 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1441285 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\SDP\\DR\\gamma Dataset\\train... found 24192 images in 5 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\SDP\\DR\\gamma Dataset\\val... found 663 images in 5 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\SDP\\DR\\gamma Dataset\\val... 663 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 663/663 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42/42 [00:09<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.836          1\n",
      "Speed: 0.7ms preprocess, 4.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\val6\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO('yolov8n-cls.pt')  # load an official model\n",
    "model = YOLO('runs/classify/train18/weights/best.pt')  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1   # top1 accuracy\n",
    "metrics.top5   # top5 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "efe5ceec-a6d8-4eb0-9c57-fde43782997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Open the image\n",
    "image = Image.open('Dataset sampled/val/Mild DR/e2a233493b90.png')\n",
    "\n",
    "# Resize the image to match the model's input size (64x64)\n",
    "resized_image = image.resize((64, 64))\n",
    "\n",
    "# Convert the resized image to a tensor\n",
    "# Assuming you are using PyTorch\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to PyTorch Tensor\n",
    "])\n",
    "\n",
    "input_tensor = transform(resized_image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Now, input_tensor should have the shape [1, 3, 64, 64], which matches the expected input size of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1d39238f-407c-4047-a792-8d7c8ac1a935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.17 üöÄ Python-3.8.10 torch-2.2.0+cu121 CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/classify/YOLOv8n-normal-sampled/train/weights/best.pt' with input shape (1, 3, 64, 64) BCHW and output shape(s) (1, 5) (2.8 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import load_entry_point\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx>=1.12.0\n",
      "  Downloading onnx-1.15.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
      "Requirement already satisfied: numpy in /home/ragarwal/.local/lib/python3.8/site-packages (from onnx>=1.12.0) (1.24.4)\n",
      "Collecting protobuf>=3.20.2\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Installing collected packages: protobuf, onnx\n",
      "Successfully installed onnx-1.15.0 protobuf-4.25.3\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 10.2s, installed 1 package: ['onnx>=1.12.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 10.5s, saved as 'runs/classify/YOLOv8n-normal-sampled/train/weights/best.onnx' (5.5 MB)\n",
      "\n",
      "Export complete (11.6s)\n",
      "Results saved to \u001b[1m/home/ragarwal/DR/runs/classify/YOLOv8n-normal-sampled/train/weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=runs/classify/YOLOv8n-normal-sampled/train/weights/best.onnx imgsz=64  \n",
      "Validate:        yolo val task=classify model=runs/classify/YOLOv8n-normal-sampled/train/weights/best.onnx imgsz=64 data=Dataset sampled  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs/classify/YOLOv8n-normal-sampled/train/weights/best.onnx'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = YOLO('path/to/best.pt')  # load a custom trained model\n",
    "\n",
    "# Export the model\n",
    "model.export(format='onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d39bca90-04cf-4f9a-9c2c-0c6c951e3d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = YOLO('/home/ragarwal/DR/runs/classify/YOLOv8n-normal-sampled/train/weights/best.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1f6d9381-2e0e-4898-8b80-38baba3df86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.17 üöÄ Python-3.8.10 torch-2.2.0+cu121 CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/classify/YOLOv8n-normal-sampled/train/weights/best.pt' with input shape (1, 3, 64, 64) BCHW and output shape(s) (1, 5) (2.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.2s, saved as 'runs/classify/YOLOv8n-normal-sampled/train/weights/best.onnx' (5.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['openvino-dev>=2023.0'] not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import load_entry_point\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openvino-dev>=2023.0\n",
      "  Downloading openvino_dev-2023.3.0-13775-py3-none-any.whl (5.9 MB)\n",
      "Collecting addict>=2.4.0\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /home/ragarwal/.local/lib/python3.8/site-packages (from openvino-dev>=2023.0) (0.7.1)\n",
      "Collecting jstyleson>=0.0.2\n",
      "  Downloading jstyleson-0.0.2.tar.gz (2.0 kB)\n",
      "Requirement already satisfied: networkx<=3.1.0 in /home/ragarwal/.local/lib/python3.8/site-packages (from openvino-dev>=2023.0) (3.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/ragarwal/.local/lib/python3.8/site-packages (from openvino-dev>=2023.0) (1.24.4)\n",
      "Requirement already satisfied: opencv-python in /home/ragarwal/.local/lib/python3.8/site-packages (from openvino-dev>=2023.0) (4.9.0.80)\n",
      "Requirement already satisfied: openvino-telemetry>=2022.1.0 in /home/ragarwal/.local/lib/python3.8/site-packages (from openvino-dev>=2023.0) (2023.2.1)\n",
      "Requirement already satisfied: pillow>=8.1.2 in /home/ragarwal/.local/lib/python3.8/site-packages (from openvino-dev>=2023.0) (10.2.0)\n",
      "Collecting pyyaml>=5.4.1\n",
      "  Downloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\n",
      "Requirement already satisfied: requests>=2.25.1 in /home/ragarwal/.local/lib/python3.8/site-packages (from openvino-dev>=2023.0) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.8 in /home/ragarwal/.local/lib/python3.8/site-packages (from openvino-dev>=2023.0) (1.10.1)\n",
      "Collecting texttable>=1.6.3\n",
      "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm>=4.54.1 in /home/ragarwal/.local/lib/python3.8/site-packages (from openvino-dev>=2023.0) (4.66.2)\n",
      "Requirement already satisfied: openvino==2023.3.0 in /home/ragarwal/.local/lib/python3.8/site-packages (from openvino-dev>=2023.0) (2023.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ragarwal/.local/lib/python3.8/site-packages (from requests>=2.25.1->openvino-dev>=2023.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.25.1->openvino-dev>=2023.0) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.25.1->openvino-dev>=2023.0) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.25.1->openvino-dev>=2023.0) (2019.11.28)\n",
      "Building wheels for collected packages: jstyleson\n",
      "  Building wheel for jstyleson (setup.py): started\n",
      "  Building wheel for jstyleson (setup.py): finished with status 'done'\n",
      "  Created wheel for jstyleson: filename=jstyleson-0.0.2-py3-none-any.whl size=2384 sha256=0b2a1acbd03df096124f2c169ad2da87284e80e1c0ac41b0facaa1f4f4576eb7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8qt1exnp/wheels/c6/3a/8e/dad087c08bb0e4c94d03433ccc0972ee29707dff8e6c5f5e1b\n",
      "Successfully built jstyleson\n",
      "Installing collected packages: addict, jstyleson, pyyaml, texttable, openvino-dev\n",
      "Successfully installed addict-2.4.0 jstyleson-0.0.2 openvino-dev-2023.3.0 pyyaml-6.0.1 texttable-1.7.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 9.8s, installed 1 package: ['openvino-dev>=2023.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2023.3.0-13775-ceeafaf64f3-releases/2023/3...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success ‚úÖ 10.6s, saved as 'runs/classify/YOLOv8n-normal-sampled/train/weights/best_openvino_model/' (5.6 MB)\n",
      "\n",
      "Export complete (11.9s)\n",
      "Results saved to \u001b[1m/home/ragarwal/DR/runs/classify/YOLOv8n-normal-sampled/train/weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=runs/classify/YOLOv8n-normal-sampled/train/weights/best_openvino_model imgsz=64  \n",
      "Validate:        yolo val task=classify model=runs/classify/YOLOv8n-normal-sampled/train/weights/best_openvino_model imgsz=64 data=Dataset sampled  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs/classify/YOLOv8n-normal-sampled/train/weights/best_openvino_model'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format='openvino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7e847ea6-4698-4dc1-bc7d-ea421966f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_model = YOLO('runs/classify/YOLOv8n-normal-sampled/train/weights/best_openvino_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2053eff6-069e-4ae8-b989-996e2299090c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ragarwal/DR/Dataset sampled/val/Mild DR/e2a233493b90.png: 64x64 Mild DR 0.85, Moderate DR 0.09, Proliferate DR 0.03, No DR 0.02, Severe DR 0.00, 2.9ms\n",
      "Speed: 1.7ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "original_result=model.predict('Dataset sampled/val/Mild DR/e2a233493b90.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "febf3da2-33d5-4af0-9ca7-3bcd61d98019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 64x64 Mild DR 0.85, Moderate DR 0.10, Proliferate DR 0.03, No DR 0.02, Severe DR 0.00, 1.1ms\n",
      "Speed: 0.0ms preprocess, 1.1ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "onnx_result=onnx_model.predict(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4a0a00bb-635e-4080-8071-e7aba68e1cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 64x64 Mild DR 0.85, Moderate DR 0.10, Proliferate DR 0.03, No DR 0.02, Severe DR 0.00, 1.9ms\n",
      "Speed: 0.0ms preprocess, 1.9ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "results_ov = ov_model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3e21b71b-4859-4475-9b6e-87ec7fc50f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Open the image\n",
    "image = Image.open('Dataset sampled/val/Severe DR/432.jpg')\n",
    "\n",
    "# Resize the image to match the model's input size (64x64)\n",
    "resized_image = image.resize((64, 64))\n",
    "\n",
    "# Convert the resized image to a tensor\n",
    "# Assuming you are using PyTorch\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to PyTorch Tensor\n",
    "])\n",
    "\n",
    "input_tensor = transform(resized_image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Now, input_tensor should have the shape [1, 3, 64, 64], which matches the expected input size of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7fa99db5-4feb-48fe-a3f7-0c788360abc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ragarwal/DR/Dataset sampled/val/Severe DR/432.jpg: 64x64 Severe DR 0.67, Proliferate DR 0.22, No DR 0.10, Moderate DR 0.01, Mild DR 0.00, 2.6ms\n",
      "Speed: 22.2ms preprocess, 2.6ms inference, 0.0ms postprocess per image at shape (1, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "original_result=model.predict('Dataset sampled/val/Severe DR/432.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "15f26e29-9005-4af3-92c2-90533643341e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 64x64 Severe DR 0.79, No DR 0.10, Proliferate DR 0.10, Moderate DR 0.00, Mild DR 0.00, 1.1ms\n",
      "Speed: 0.0ms preprocess, 1.1ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "onnx_result=onnx_model.predict(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3c09c5f4-ffeb-4e52-bf1a-a03b71641d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 64x64 Severe DR 0.79, No DR 0.10, Proliferate DR 0.10, Moderate DR 0.00, Mild DR 0.00, 1.9ms\n",
      "Speed: 0.0ms preprocess, 1.9ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "results_ov = ov_model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9a2044af-a2ef-4f80-9f27-aec71b89361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Open the image\n",
    "image = Image.open('Dataset sampled/val/Proliferate DR/640.jpg')\n",
    "\n",
    "# Resize the image to match the model's input size (64x64)\n",
    "resized_image = image.resize((64, 64))\n",
    "\n",
    "# Convert the resized image to a tensor\n",
    "# Assuming you are using PyTorch\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to PyTorch Tensor\n",
    "])\n",
    "\n",
    "input_tensor = transform(resized_image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Now, input_tensor should have the shape [1, 3, 64, 64], which matches the expected input size of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1000aa4d-c4d5-4cbd-92e0-f8eeeaadcd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 64x64 Proliferate DR 1.00, Moderate DR 0.00, Severe DR 0.00, No DR 0.00, Mild DR 0.00, 2.2ms\n",
      "Speed: 0.0ms preprocess, 2.2ms inference, 0.1ms postprocess per image at shape (1, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "original_result=model.predict(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e41abe71-65c7-4907-8623-a2b902f01293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 64x64 Proliferate DR 1.00, Moderate DR 0.00, Severe DR 0.00, No DR 0.00, Mild DR 0.00, 1.1ms\n",
      "Speed: 0.0ms preprocess, 1.1ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "onnx_result=onnx_model.predict(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b1f8b0f3-f2e7-4e24-b445-4aa7e5f08859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 64x64 Proliferate DR 1.00, Moderate DR 0.00, Severe DR 0.00, No DR 0.00, Mild DR 0.00, 1.8ms\n",
      "Speed: 0.0ms preprocess, 1.8ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "results_ov = ov_model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d6023-e25d-4f00-8094-b9515e4dff7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
